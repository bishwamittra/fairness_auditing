---
layout: about
title: About
permalink: /
subtitle: <a href='#'>IJCAI Tutorial 2023</a>. Macao

# profile:
#   align: right
#   image: prof_pic.jpg
#   image_circular: false # crops the image to make it circular
#   address: >
#     <p>555 your office number</p>
#     <p>123 your address street</p>
#     <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page


---

Any publicly used technology presently undergoes an audit mechanism, where we aim to understand the impacts and limitations of using that technology, and why they are caused. As Machine Learning (ML) is becoming the pervasive technology of our time and the discourse on bias induced by ML systems is attracting attention, it is a genuine concern to understand how to audit an ML system. In this tutorial, we discuss algorithmic developments and existing software to 

1. choose a compatible fairness metric to quantify bias encountered in an application,
2.  quantify the bias encountered in the predictions of ML systems accurately and sample-efficiently, and
3.  explain different sources yield-ing the bias.